{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1000)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to mnist\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:18<00:00, 523kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist\\MNIST\\raw\\train-images-idx3-ubyte.gz to mnist\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1000)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to mnist\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 228kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist\\MNIST\\raw\\train-labels-idx1-ubyte.gz to mnist\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1000)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to mnist\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.65M/1.65M [00:02<00:00, 575kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to mnist\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1000)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to mnist\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.54k/4.54k [00:00<?, ?B/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to mnist\\MNIST\\raw\n",
      "\n",
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# generate the MNIST dataset\n",
    "transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])\n",
    "mnist_dset = torchvision.datasets.MNIST(\"mnist\", download=True, transform=transforms)\n",
    "print(mnist_dset[0][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample from MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show a sample\n",
    "import matplotlib.pyplot as plt\n",
    "# the first index is for the dataset, the second is for the tuple, the third one is for channel\n",
    "\n",
    "\n",
    "f, axarr = plt.subplots(2,2)\n",
    "axarr[0,0].imshow(mnist_dset[0][0][0], cmap='gray')\n",
    "axarr[0,1].imshow(mnist_dset[1][0][0], cmap='gray')\n",
    "axarr[1,0].imshow(mnist_dset[20][0][0], cmap='gray')\n",
    "axarr[1,1].imshow(mnist_dset[23][0][0], cmap='gray')\n",
    "axarr[0,0].axis('off')\n",
    "axarr[0,1].axis('off')\n",
    "axarr[1,0].axis('off')\n",
    "axarr[1,1].axis('off')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScoreNetwork0(torch.nn.Module):\n",
    "    # takes an input image and time, returns the score function\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        nch = 2\n",
    "        chs = [32, 64, 128, 256, 256]\n",
    "        self._convs = torch.nn.ModuleList([\n",
    "            torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(2, chs[0], kernel_size=3, padding=1),  # (batch, ch, 28, 28)\n",
    "                torch.nn.LogSigmoid(),  # (batch, 8, 28, 28)\n",
    "            ),\n",
    "            torch.nn.Sequential(\n",
    "                torch.nn.MaxPool2d(kernel_size=2, stride=2),  # (batch, ch, 14, 14)\n",
    "                torch.nn.Conv2d(chs[0], chs[1], kernel_size=3, padding=1),  # (batch, ch, 14, 14)\n",
    "                torch.nn.LogSigmoid(),  # (batch, 16, 14, 14)\n",
    "            ),\n",
    "            torch.nn.Sequential(\n",
    "                torch.nn.MaxPool2d(kernel_size=2, stride=2),  # (batch, ch, 7, 7)\n",
    "                torch.nn.Conv2d(chs[1], chs[2], kernel_size=3, padding=1),  # (batch, ch, 7, 7)\n",
    "                torch.nn.LogSigmoid(),  # (batch, 32, 7, 7)\n",
    "            ),\n",
    "            torch.nn.Sequential(\n",
    "                torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=1),  # (batch, ch, 4, 4)\n",
    "                torch.nn.Conv2d(chs[2], chs[3], kernel_size=3, padding=1),  # (batch, ch, 4, 4)\n",
    "                torch.nn.LogSigmoid(),  # (batch, 64, 4, 4)\n",
    "            ),\n",
    "            torch.nn.Sequential(\n",
    "                torch.nn.MaxPool2d(kernel_size=2, stride=2),  # (batch, ch, 2, 2)\n",
    "                torch.nn.Conv2d(chs[3], chs[4], kernel_size=3, padding=1),  # (batch, ch, 2, 2)\n",
    "                torch.nn.LogSigmoid(),  # (batch, 64, 2, 2)\n",
    "            ),\n",
    "        ])\n",
    "        self._tconvs = torch.nn.ModuleList([\n",
    "            torch.nn.Sequential(\n",
    "                # input is the output of convs[4]\n",
    "                torch.nn.ConvTranspose2d(chs[4], chs[3], kernel_size=3, stride=2, padding=1, output_padding=1),  # (batch, 64, 4, 4)\n",
    "                torch.nn.LogSigmoid(),\n",
    "            ),\n",
    "            torch.nn.Sequential(\n",
    "                # input is the output from the above sequential concated with the output from convs[3]\n",
    "                torch.nn.ConvTranspose2d(chs[3] * 2, chs[2], kernel_size=3, stride=2, padding=1, output_padding=0),  # (batch, 32, 7, 7)\n",
    "                torch.nn.LogSigmoid(),\n",
    "            ),\n",
    "            torch.nn.Sequential(\n",
    "                # input is the output from the above sequential concated with the output from convs[2]\n",
    "                torch.nn.ConvTranspose2d(chs[2] * 2, chs[1], kernel_size=3, stride=2, padding=1, output_padding=1),  # (batch, chs[2], 14, 14)\n",
    "                torch.nn.LogSigmoid(),\n",
    "            ),\n",
    "            torch.nn.Sequential(\n",
    "                # input is the output from the above sequential concated with the output from convs[1]\n",
    "                torch.nn.ConvTranspose2d(chs[1] * 2, chs[0], kernel_size=3, stride=2, padding=1, output_padding=1),  # (batch, chs[1], 28, 28)\n",
    "                torch.nn.LogSigmoid(),\n",
    "            ),\n",
    "            torch.nn.Sequential(\n",
    "                # input is the output from the above sequential concated with the output from convs[0]\n",
    "                torch.nn.Conv2d(chs[0] * 2, chs[0], kernel_size=3, padding=1),  # (batch, chs[0], 28, 28)\n",
    "                torch.nn.LogSigmoid(),\n",
    "                torch.nn.Conv2d(chs[0], 1, kernel_size=3, padding=1),  # (batch, 1, 28, 28)\n",
    "            ),\n",
    "        ])\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (..., ch0 * 28 * 28), t: (..., 1)\n",
    "        x2 = torch.reshape(x, (*x.shape[:-1], 1, 28, 28))  # (..., ch0, 28, 28)\n",
    "        tt = t[..., None, None].expand(*t.shape[:-1], 1, 28, 28)  # (..., 1, 28, 28)\n",
    "        x2t = torch.cat((x2, tt), dim=-3)\n",
    "        signal = x2t\n",
    "        signals = []\n",
    "        for i, conv in enumerate(self._convs):\n",
    "            signal = conv(signal)\n",
    "            if i < len(self._convs) - 1:\n",
    "                signals.append(signal)\n",
    "\n",
    "        for i, tconv in enumerate(self._tconvs):\n",
    "            if i == 0:\n",
    "                signal = tconv(signal)\n",
    "            else:\n",
    "                signal = torch.cat((signal, signals[-i]), dim=-3)\n",
    "                signal = tconv(signal)\n",
    "        signal = torch.reshape(signal, (*signal.shape[:-3], -1))  # (..., 1 * 28 * 28)\n",
    "        return signal\n",
    "\n",
    "score_network = ScoreNetwork0()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(score_network: torch.nn.Module, x: torch.Tensor) -> torch.Tensor:\n",
    "    # x: (batch_size, nch) is the training data\n",
    "    \n",
    "    # sample the time\n",
    "    t = torch.rand((x.shape[0], 1), dtype=x.dtype, device=x.device) * (1 - 1e-4) + 1e-4\n",
    "\n",
    "    # calculate the terms for the posterior log distribution\n",
    "    int_beta = (0.1 + 0.5 * (20 - 0.1) * t) * t  # integral of beta\n",
    "    mu_t = x * torch.exp(-0.5 * int_beta)\n",
    "    var_t = -torch.expm1(-int_beta)\n",
    "    x_t = torch.randn_like(x) * var_t ** 0.5 + mu_t\n",
    "    grad_log_p = -(x_t - mu_t) / var_t  # (batch_size, nch)\n",
    "\n",
    "    # calculate the score function\n",
    "    score = score_network(x_t, t)  # score: (batch_size, nch)\n",
    "\n",
    "    # calculate the loss function\n",
    "    loss = (score - grad_log_p) ** 2\n",
    "    lmbda_t = var_t\n",
    "    weighted_loss = lmbda_t * loss\n",
    "    return torch.mean(weighted_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start the training loop\n",
    "import time\n",
    "opt = torch.optim.Adam(score_network.parameters(), lr=3e-4)\n",
    "dloader = torch.utils.data.DataLoader(mnist_dset, batch_size=64, shuffle=True)\n",
    "device = torch.device('cuda:0')  # change this if you don't have a gpu\n",
    "score_network = score_network.to(device)\n",
    "t0 = time.time()\n",
    "for i_epoch in range(400):\n",
    "    total_loss = 0\n",
    "    for data, _ in dloader:  # we don't need the data class\n",
    "        data = data.reshape(data.shape[0], -1).to(device)\n",
    "        opt.zero_grad()\n",
    "\n",
    "        # training step\n",
    "        loss = calc_loss(score_network, data)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        # running stats\n",
    "        total_loss = total_loss + loss.detach().item() * data.shape[0]\n",
    "\n",
    "    # print the training stats\n",
    "    if i_epoch % 20 == 0:\n",
    "        print(f\"{i_epoch} ({time.time() - t0}s): {total_loss / len(mnist_dset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
