torch.Size([1, 28, 28])
Epoch 0, Loss: 0.23730271278619766
Epoch 20, Loss: 0.02717617388168971
Epoch 40, Loss: 0.02174120079378287
Epoch 60, Loss: 0.020374077995618186
Epoch 80, Loss: 0.019070367747048535
Epoch 100, Loss: 0.018091246086359022
Epoch 120, Loss: 0.017596078391869864
Epoch 140, Loss: 0.017157829014956952
Epoch 160, Loss: 0.017123423785964646
Epoch 180, Loss: 0.016677486874659857
Epoch 200, Loss: 0.016520770510037742
Epoch 220, Loss: 0.016605006432533265
Epoch 240, Loss: 0.016409249523778757
Epoch 260, Loss: 0.01603795144657294
Epoch 280, Loss: 0.0161364841307203
Epoch 300, Loss: 0.01590039804528157
Epoch 320, Loss: 0.015684397830069065
Epoch 340, Loss: 0.015655016926427682
Epoch 360, Loss: 0.015600594374537468
Epoch 380, Loss: 0.015386623713374138
Epoch 400, Loss: 0.01623110763579607
Epoch 420, Loss: 0.015674715621272723
Epoch 440, Loss: 0.015324985685944557
Epoch 460, Loss: 0.015607178675631682
Epoch 480, Loss: 0.015720680582523346

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 23131090: <mnist_training> in cluster <dcc> Done

Job <mnist_training> was submitted from host <hpclogin1> by user <s204427> in cluster <dcc> at Mon Nov 11 15:46:57 2024
Job was executed on host(s) <4*n-62-12-22>, in queue <gpua100>, as user <s204427> in cluster <dcc> at Mon Nov 11 16:46:14 2024
</zhome/1a/a/156609> was used as the home directory.
</zhome/1a/a/156609/project/path> was used as the working directory.
Started at Mon Nov 11 16:46:14 2024
Terminated at Mon Nov 11 17:54:06 2024
Results reported at Mon Nov 11 17:54:06 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
# mnist_job.sh
#!/bin/bash
#BSUB -J mnist_training           # Job name
#BSUB -q gpua100                   # Queue name for Tesla A10 GPUs
#BSUB -gpu "num=1"                # Request 1 GPU in exclusive mode
#BSUB -n 4                        # Request 4 CPU cores (required)
#BSUB -R "span[hosts=1]"          # Ensure resources are on a single node
#BSUB -W 05:00                    # Walltime (1 hour)
#BSUB -R "rusage[mem=4096]"       # Request 4GB of system memory
#BSUB -o output_%J.log            # Output file
#BSUB -e error_%J.log             # Error file

# Load necessary modules
module load python3/3.10.12
module load cuda/12.1

# Set W&B API key (replace with your actual key)
export WANDB_API_KEY="6ecda4c80f57815b4ff4780014d596e19617454c"

# Activate virtual environment
source /zhome/1a/a/156609/project/path/.venv/bin/activate

# Run the PyTorch training script
python3 model1.py

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   4051.00 sec.
    Max Memory :                                 799 MB
    Average Memory :                             770.36 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               15585.00 MB
    Max Swap :                                   -
    Max Processes :                              6
    Max Threads :                                27
    Run time :                                   4071 sec.
    Turnaround time :                            7629 sec.

The output (if any) is above this job summary.



PS:

Read file <error_23131090.log> for stderr output of this job.

